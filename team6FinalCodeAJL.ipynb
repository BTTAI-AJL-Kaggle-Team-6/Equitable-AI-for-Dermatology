{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0828962-26f6-4142-b778-bf922f8cbe55",
   "metadata": {},
   "source": [
    "# Extracting Files from a Zip Archive\n",
    "\n",
    "\n",
    "\n",
    "1. **Import Modules:**\n",
    "   - Imports the `zipfile` module to work with zip archives.\n",
    "   - Imports the `os` module for interacting with the file system.\n",
    "\n",
    "2. **Define Paths:**\n",
    "   - `zip_file_path` is the path to the zip file you want to extract. (Adjust this as needed.)\n",
    "   - `extract_dir` is the directory where the extracted files will be stored.\n",
    "\n",
    "3. **Create Extraction Directory:**\n",
    "   - Uses `os.makedirs()` with `exist_ok=True` to ensure the extraction directory exists (it creates the directory if it doesn't).\n",
    "\n",
    "4. **Extract the Zip File:**\n",
    "   - Opens the zip file in read mode using a context manager.\n",
    "   - Extracts all the contents of the zip file into the specified extraction directory using `extractall()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bac126d8-bb59-4f4e-b1c7-f131a9ae799a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files extracted to: extracted_files\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import os\n",
    "\n",
    "# Path to the zip file (adjust accordingly)\n",
    "zip_file_path = \"bttai-ajl-2025.zip\"\n",
    "\n",
    "# Directory where you want to extract the contents\n",
    "extract_dir = \"extracted_files\"\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "os.makedirs(extract_dir, exist_ok=True)\n",
    "\n",
    "# Open the zip file and extract all contents\n",
    "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extract_dir)\n",
    "\n",
    "print(f\"Files extracted to: {extract_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "451ecbbe-83e3-482d-9c53-f8dc8cfd28ec",
   "metadata": {},
   "source": [
    "# Loading and Preprocessing the Skin Disease Dataset\n",
    "\n",
    "This code snippet sets up the environment for training a model on a skin disease dataset. It performs the following steps:\n",
    "\n",
    "1. **Import Libraries:**\n",
    "   - `torch` for deep learning operations.\n",
    "   - `pandas` for data manipulation.\n",
    "   - `os` for file path operations.\n",
    "   - `torchvision.transforms` for image pre-processing and augmentation.\n",
    "   - `torch.utils.data.Dataset` and `DataLoader` for creating and handling datasets.\n",
    "   - `PIL.Image` for image processing.\n",
    "   - `sklearn.utils.class_weight` for computing class weights (if needed).\n",
    "   - `numpy` for numerical operations.\n",
    "\n",
    "2. **Set Device:**\n",
    "   - Checks if a CUDA-enabled GPU is available. If yes, it uses the GPU; otherwise, it falls back to the CPU.\n",
    "   - Prints the device being used.\n",
    "\n",
    "3. **Define Dataset Paths:**\n",
    "   - `DATASET_FOLDER` is the root folder containing the dataset.\n",
    "   - `TRAIN_IMG_DIR` specifies the directory where training images are stored.\n",
    "   - `TRAIN_CSV` is the path to the CSV file that contains image metadata and labels.\n",
    "\n",
    "4. **Define Image Transformations:**\n",
    "   - Resizes images to 224x224 pixels.\n",
    "   - Applies random horizontal flipping and random rotation (up to 10 degrees) for data augmentation.\n",
    "   - Adjusts brightness and contrast with `ColorJitter`.\n",
    "   - Converts images to PyTorch tensors.\n",
    "   - Normalizes the images with a mean and standard deviation of 0.5 across all channels.\n",
    "\n",
    "5. **Custom Dataset Class (`SkinDiseaseDataset`):**\n",
    "   - Reads the CSV file using pandas to get image metadata and labels.\n",
    "   - Creates a mapping from original text labels to numeric indices.\n",
    "   - In the `__getitem__` method:\n",
    "     - Constructs the image filename using the `md5hash` field.\n",
    "     - Builds the full path to the image file, which is organized by label directories.\n",
    "     - Opens the image and converts it to RGB.\n",
    "     - Applies the defined transformations.\n",
    "     - Returns the transformed image and its encoded label as a tensor.\n",
    "\n",
    "6. **Load Dataset and Create DataLoader:**\n",
    "   - Instantiates the `SkinDiseaseDataset` with the CSV path, image directory, and transformation pipeline.\n",
    "   - Creates a `DataLoader` with a specified batch size (32) and shuffling enabled to iterate over the dataset during training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b59ae452-0e2f-4b0b-a2e8-0b69c8766d28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import os\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# Dataset paths\n",
    "DATASET_FOLDER = \"extracted_files\"\n",
    "TRAIN_IMG_DIR = os.path.join(DATASET_FOLDER, \"train\", \"train\")\n",
    "TRAIN_CSV = os.path.join(DATASET_FOLDER, \"train.csv\")\n",
    "\n",
    "# Define Transformations (224x224 + Data Augmentation)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "# Custom Dataset\n",
    "class SkinDiseaseDataset(Dataset):\n",
    "    def __init__(self, csv_path, img_dir, transform=None):\n",
    "        self.data = pd.read_csv(csv_path)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.label_mapping = {label: idx for idx, label in enumerate(sorted(self.data['label'].unique()))}\n",
    "        self.data['label_encoded'] = self.data['label'].map(self.label_mapping)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.data.iloc[idx]['md5hash'] + \".jpg\"\n",
    "        label = torch.tensor(self.data.iloc[idx]['label_encoded'], dtype=torch.long)\n",
    "        img_path = os.path.join(self.img_dir, self.data.iloc[idx]['label'], img_name)\n",
    "\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "# Load Dataset\n",
    "train_dataset = SkinDiseaseDataset(TRAIN_CSV, TRAIN_IMG_DIR, transform=transform)\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7fab2c7-4063-4190-ac73-01b1e6d88e41",
   "metadata": {},
   "source": [
    "# Selecting the Compute Device\n",
    "\n",
    "This section determines the appropriate compute device based on your system's hardware capabilities:\n",
    "\n",
    "1. **Check for Mac M1/M2 (MPS) Support:**\n",
    "   - Uses `torch.backends.mps.is_available()` to check if the Metal Performance Shaders (MPS) backend is available.\n",
    "   - Sets the device to `\"mps\"` to leverage the Metal API on Mac M1/M2 systems.\n",
    "\n",
    "2. **Check for CUDA Availability:**\n",
    "   - If MPS is not available, it checks whether a CUDA-capable GPU is available with `torch.cuda.is_available()`.\n",
    "   - If available, sets the device to `\"cuda\"`.\n",
    "\n",
    "3. **Default to CPU:**\n",
    "   - If neither MPS nor CUDA is available, defaults to using the CPU.\n",
    "\n",
    "4. **Print the Selected Device:**\n",
    "   - Displays the selected device to confirm which hardware will be used for computations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3455862-01b1-4cf7-8d99-db30fdcfaff4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "# Set device for Mac M1/M2 (MPS) or CUDA\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")  # Use Metal API on Mac M1/M2\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")  # Use CUDA if available\n",
    "else:\n",
    "    device = torch.device(\"cpu\")  # Default to CPU\n",
    "\n",
    "print(\"Using device:\", device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc213c0f-406d-49da-ad7a-bb16282b4305",
   "metadata": {},
   "source": [
    "\n",
    "# Fine-tuning a Pre-trained ResNet-50 Model\n",
    "\n",
    "This section prepares a pre-trained ResNet-50 model for transfer learning on your custom skin disease dataset:\n",
    "\n",
    "1. **Import Required Modules:**\n",
    "   - Imports `torch.nn` for defining neural network layers.\n",
    "   - Imports `torchvision.models` to load pre-trained models.\n",
    "\n",
    "2. **Load Pre-trained Model:**\n",
    "   - Loads the ResNet-50 model with weights pre-trained on the ImageNet dataset using the updated PyTorch 2.0+ syntax.\n",
    "\n",
    "3. **Freeze Pre-trained Layers:**\n",
    "   - Iterates through all parameters in the model and disables gradient updates (i.e., `requires_grad = False`) to preserve learned features and speed up training.\n",
    "\n",
    "4. **Modify the Final Classification Layer:**\n",
    "   - Retrieves the number of input features from the original fully connected layer.\n",
    "   - Replaces the final layer with a new `nn.Linear` layer configured to output a number of classes equal to the length of `train_dataset.label_mapping`.\n",
    "\n",
    "5. **Device Configuration and Data Type Fix:**\n",
    "   - Moves the model to the selected device (MPS, CUDA, or CPU) for computation.\n",
    "   - Converts the model to `float32` to address potential data type issues on the MPS backend.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b8ef1e1-3866-4f29-bc56-feef5000ecb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "\n",
    "# Load Pre-trained ResNet-50 Model\n",
    "model = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)  # Updated syntax for PyTorch 2.0+\n",
    "\n",
    "# Freeze all layers except the last fully connected layer (speeds up training)\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Modify the Final Classification Layer (to match your dataset's classes)\n",
    "num_features = model.fc.in_features\n",
    "model.fc = nn.Linear(num_features, len(train_dataset.label_mapping))  # New classification layer\n",
    "\n",
    "# Move Model to MPS & Convert to float32\n",
    "model = model.to(device)\n",
    "model = model.to(torch.float32)  # Fix MPS dtype issue\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed0fba0-cf0e-42c3-a2af-39c9ba974a3c",
   "metadata": {},
   "source": [
    "\n",
    "# Handling Imbalanced Data with Class Weights\n",
    "\n",
    "This code snippet addresses class imbalance in the dataset by:\n",
    "\n",
    "1. **Extracting Labels:**\n",
    "   - Retrieves the label values from the dataset's CSV.\n",
    "\n",
    "2. **Computing Class Weights:**\n",
    "   - Uses `compute_class_weight` with the `\"balanced\"` option from scikit-learn.\n",
    "   - Calculates weights for each class based on their frequency in the dataset.\n",
    "\n",
    "3. **Preparing Weights for PyTorch:**\n",
    "   - Converts the computed class weights to a PyTorch tensor with type `float`.\n",
    "   - Moves the tensor to the selected computation device (MPS, CUDA, or CPU).\n",
    "\n",
    "4. **Defining a Weighted Loss Function:**\n",
    "   - Sets up `nn.CrossEntropyLoss` with the class weights.\n",
    "   - This helps to penalize errors on minority classes more during training, thus handling imbalance.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f0e713ec-3586-461b-be45-298e50b2ebf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Class Weights to Handle Imbalanced Data\n",
    "labels = train_dataset.data[\"label\"].values\n",
    "class_weights = compute_class_weight(\"balanced\", classes=np.unique(labels), y=labels)\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
    "\n",
    "# Define Loss Function with Weights\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "bb0e20f4-d56e-485b-8e00-216eaf8da144",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Class Weights to Handle Imbalanced Data\n",
    "labels = train_dataset.data[\"label\"].values\n",
    "class_weights = compute_class_weight(\"balanced\", classes=np.unique(labels), y=labels)\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
    "\n",
    "# Define Loss Function with Weights\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36674021-d7be-43fa-979c-c3e884a40eb9",
   "metadata": {},
   "source": [
    "# Configuring the Optimizer and Learning Rate Scheduler\n",
    "\n",
    "This section sets up the training optimization process:\n",
    "\n",
    "1. **Optimizer Setup:**\n",
    "   - **AdamW Optimizer:**  \n",
    "     Uses `AdamW`, a variant of the Adam optimizer that includes weight decay for better regularization.\n",
    "   - **Parameters:**  \n",
    "     Applies the optimizer to all model parameters with:\n",
    "     - A learning rate of 0.0005.\n",
    "     - A weight decay of 1e-4 to prevent overfitting.\n",
    "\n",
    "2. **Learning Rate Scheduler:**\n",
    "   - **StepLR Scheduler:**  \n",
    "     Reduces the learning rate by a factor of 0.5 (`gamma=0.5`) every 10 epochs (`step_size=10`).\n",
    "   - **Purpose:**  \n",
    "     Gradually lowers the learning rate during training, which helps in fine-tuning the model and stabilizing convergence.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b350ac8f-e1d8-4e76-a44a-250a23c5f15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Use AdamW Optimizer for Better Regularization\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.0005, weight_decay=1e-4)\n",
    "\n",
    "# Learning Rate Scheduler to Reduce LR Over Time\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d97e20-60d7-4360-a77c-0cf8834d81b4",
   "metadata": {},
   "source": [
    "# Training Loop Overview\n",
    "\n",
    "This code block trains the model over 50 epochs. Below is a breakdown of the process:\n",
    "\n",
    "- **Number of Epochs:**  \n",
    "  - `num_epochs = 50` sets the training to run for 50 complete passes over the dataset.\n",
    "\n",
    "- **Epoch Loop:**  \n",
    "  - For each epoch, the model is set to training mode using `model.train()`.\n",
    "  - A `running_loss` variable is initialized to accumulate the loss over all batches in the current epoch.\n",
    "\n",
    "- **Batch Processing:**  \n",
    "  - Iterates over batches from the `train_loader`.\n",
    "  - Moves the input images and labels to the selected device (GPU/MPS/CPU).\n",
    "  - Ensures that images are cast to `float32` and labels to `long` type.\n",
    "  - Clears previous gradients with `optimizer.zero_grad()`.\n",
    "  - Computes model outputs by passing the images through the model.\n",
    "  - Calculates the loss using the defined criterion (e.g., weighted CrossEntropyLoss).\n",
    "  - Performs backpropagation with `loss.backward()`.\n",
    "  - Updates model parameters using `optimizer.step()`.\n",
    "  - Accumulates the batch loss into `running_loss`.\n",
    "\n",
    "- **Learning Rate Scheduling:**  \n",
    "  - After processing all batches in an epoch, the scheduler updates the learning rate with `scheduler.step()`, gradually reducing it over time.\n",
    "\n",
    "- **Progress Reporting:**  \n",
    "  - Prints the average loss for each epoch to monitor training progress.\n",
    "\n",
    "- **Training Completion:**  \n",
    "  - After all epochs are completed, a message `\"Training Complete!\"` is printed to indicate that the training process is finished.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c52f7f6b-08c5-41b1-b795-0fbc0bdd03cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Loss: 2.8618\n",
      "Epoch 2/50, Loss: 2.3967\n",
      "Epoch 3/50, Loss: 2.1586\n",
      "Epoch 4/50, Loss: 2.0221\n",
      "Epoch 5/50, Loss: 1.9227\n",
      "Epoch 6/50, Loss: 1.8360\n",
      "Epoch 7/50, Loss: 1.7422\n",
      "Epoch 8/50, Loss: 1.6961\n",
      "Epoch 9/50, Loss: 1.6638\n",
      "Epoch 10/50, Loss: 1.6083\n",
      "Epoch 11/50, Loss: 1.5519\n",
      "Epoch 12/50, Loss: 1.5317\n",
      "Epoch 13/50, Loss: 1.5082\n",
      "Epoch 14/50, Loss: 1.4865\n",
      "Epoch 15/50, Loss: 1.4624\n",
      "Epoch 16/50, Loss: 1.4831\n",
      "Epoch 17/50, Loss: 1.4622\n",
      "Epoch 18/50, Loss: 1.4376\n",
      "Epoch 19/50, Loss: 1.4265\n",
      "Epoch 20/50, Loss: 1.4297\n",
      "Epoch 21/50, Loss: 1.3718\n",
      "Epoch 22/50, Loss: 1.3979\n",
      "Epoch 23/50, Loss: 1.3819\n",
      "Epoch 24/50, Loss: 1.3642\n",
      "Epoch 25/50, Loss: 1.3594\n",
      "Epoch 26/50, Loss: 1.3536\n",
      "Epoch 27/50, Loss: 1.3416\n",
      "Epoch 28/50, Loss: 1.3572\n",
      "Epoch 29/50, Loss: 1.3252\n",
      "Epoch 30/50, Loss: 1.3251\n",
      "Epoch 31/50, Loss: 1.3301\n",
      "Epoch 32/50, Loss: 1.3339\n",
      "Epoch 33/50, Loss: 1.3142\n",
      "Epoch 34/50, Loss: 1.3075\n",
      "Epoch 35/50, Loss: 1.3177\n",
      "Epoch 36/50, Loss: 1.3310\n",
      "Epoch 37/50, Loss: 1.3017\n",
      "Epoch 38/50, Loss: 1.3172\n",
      "Epoch 39/50, Loss: 1.3021\n",
      "Epoch 40/50, Loss: 1.2989\n",
      "Epoch 41/50, Loss: 1.3055\n",
      "Epoch 42/50, Loss: 1.3123\n",
      "Epoch 43/50, Loss: 1.3005\n",
      "Epoch 44/50, Loss: 1.2730\n",
      "Epoch 45/50, Loss: 1.2805\n",
      "Epoch 46/50, Loss: 1.2912\n",
      "Epoch 47/50, Loss: 1.2788\n",
      "Epoch 48/50, Loss: 1.2909\n",
      "Epoch 49/50, Loss: 1.2921\n",
      "Epoch 50/50, Loss: 1.2986\n",
      "Training Complete!\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 50  # Increased for better learning\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        images = images.float()  # Convert images to float32\n",
    "        labels = labels.long()   # Ensure labels are in long format\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    scheduler.step()\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss / len(train_loader):.4f}\")\n",
    "\n",
    "print(\"Training Complete!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ab23b4-d7f0-485f-8750-9994bb5aab6c",
   "metadata": {},
   "source": [
    "# Evaluating Model Performance\n",
    "\n",
    "This section evaluates the trained model using the accuracy metric:\n",
    "\n",
    "1. **Set Evaluation Mode:**\n",
    "   - `model.eval()` switches the model to evaluation mode, which disables dropout and batch normalization updates.\n",
    "\n",
    "2. **Disable Gradient Calculations:**\n",
    "   - The `torch.no_grad()` context prevents gradient computation, reducing memory usage and speeding up inference.\n",
    "\n",
    "3. **Collect Predictions and Labels:**\n",
    "   - Iterates over the data from `train_loader`.\n",
    "   - Moves images and labels to the selected device.\n",
    "   - Computes the model's outputs for the images.\n",
    "   - Uses `torch.argmax` to select the class with the highest predicted score.\n",
    "   - Accumulates predictions and true labels into `all_preds` and `all_labels` lists, converting them to NumPy arrays on the CPU.\n",
    "\n",
    "4. **Calculate Accuracy:**\n",
    "   - Uses `accuracy_score` from scikit-learn to compute the accuracy by comparing true labels with predictions.\n",
    "   - Prints the accuracy percentage.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "38f76b60-3b3c-4782-906c-07f54f3797a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 59.69%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "model.eval()  # Set model to evaluation mode\n",
    "all_preds, all_labels = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# Compute Accuracy\n",
    "accuracy = accuracy_score(all_labels, all_preds)\n",
    "print(f\"Model Accuracy: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f6f5e6-cc09-4f25-ac42-0fdc9eb73500",
   "metadata": {},
   "source": [
    "# Fine-tuning Pre-trained ResNet-50 with Partial Layer Freezing\n",
    "\n",
    "This code snippet sets up a fine-tuning pipeline using a pre-trained ResNet-50 model with the following key steps:\n",
    "\n",
    "1. **Import Required Modules:**\n",
    "   - Imports `torch.nn` for building neural network components.\n",
    "   - Imports `torchvision.models` to access pre-trained models.\n",
    "\n",
    "2. **Load the Pre-trained Model:**\n",
    "   - Loads the ResNet-50 model using weights pre-trained on the ImageNet dataset.  \n",
    "   - The syntax used (`weights=models.ResNet50_Weights.IMAGENET1K_V1`) is updated for PyTorch 2.0+.\n",
    "\n",
    "3. **Freeze Early Layers:**\n",
    "   - Freezes all layers except for the last two blocks by iterating over the parameters.\n",
    "   - The line `for param in list(model.parameters())[:-10]:` disables gradient updates (by setting `requires_grad = False`) for all parameters except the last 10, allowing the last few layers to be fine-tuned on the new dataset.\n",
    "\n",
    "4. **Modify the Final Classification Layer:**\n",
    "   - Retrieves the number of input features to the original fully connected layer (`model.fc.in_features`).\n",
    "   - Replaces the final fully connected layer with a new one (`nn.Linear`) that matches the number of classes in your dataset, as defined by `len(train_dataset.label_mapping)`.\n",
    "\n",
    "5. **Move the Model to the Device:**\n",
    "   - Transfers the model to the selected computation device (e.g., MPS, CUDA, or CPU) for training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "904854ca-7994-45b1-85e7-cffb14b0de14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "\n",
    "# Load Pre-trained ResNet-50 Model\n",
    "model = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)  # Updated for PyTorch 2.0+\n",
    "\n",
    "# Freeze all layers EXCEPT last 2 blocks (to fine-tune)\n",
    "for param in list(model.parameters())[:-10]:  # Freeze early layers\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Modify the Final Classification Layer (Adjust for Your Dataset)\n",
    "num_features = model.fc.in_features\n",
    "model.fc = nn.Linear(num_features, len(train_dataset.label_mapping))  # New classification layer\n",
    "\n",
    "# Move Model to Device\n",
    "model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8867e6c-6dc5-4514-a229-8d03a55d3229",
   "metadata": {},
   "source": [
    "# Image Transformations for ResNet-50\n",
    "\n",
    "This transformation pipeline prepares the images for use with a ResNet-50 model by performing the following steps:\n",
    "\n",
    "1. **Resize:**  \n",
    "   - `transforms.Resize((224, 224))` adjusts the image size to 224x224 pixels, matching the standard input size for ResNet-50.\n",
    "\n",
    "2. **Random Horizontal Flip:**  \n",
    "   - `transforms.RandomHorizontalFlip()` randomly flips the image horizontally, which augments the dataset and helps the model generalize better.\n",
    "\n",
    "3. **Random Rotation:**  \n",
    "   - `transforms.RandomRotation(10)` rotates the image randomly by up to 10 degrees, introducing rotational variance.\n",
    "\n",
    "4. **Color Jitter:**  \n",
    "   - `transforms.ColorJitter(brightness=0.2, contrast=0.2)` randomly alters the brightness and contrast to simulate different lighting conditions.\n",
    "\n",
    "5. **Random Affine Transformation:**  \n",
    "   - `transforms.RandomAffine(degrees=15, translate=(0.1, 0.1))` applies random affine transformations including rotations up to 15 degrees and translations up to 10% of the image dimensions to simulate distortions.\n",
    "\n",
    "6. **Conversion to Tensor:**  \n",
    "   - `transforms.ToTensor()` converts the processed image into a PyTorch tensor, making it compatible with the model.\n",
    "\n",
    "7. **Normalization:**  \n",
    "   - `transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])` normalizes the tensor by centering the values around zero with a standard deviation of 0.5 for each channel, which helps in faster and more stable training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "dae2baad-5d4b-4e72-bc16-51b7ae2176d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "# Image Transformations (ResNet-50 friendly)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),   # Randomly flip images\n",
    "    transforms.RandomRotation(10),       # Rotate images slightly\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),  # Color variations\n",
    "    transforms.RandomAffine(degrees=15, translate=(0.1, 0.1)),  # Simulated distortions\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # Normalize\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a4b539-02d5-4fed-a836-441e45dcd350",
   "metadata": {},
   "source": [
    "# DataLoader with Weighted Sampling for Class Imbalance\n",
    "\n",
    "This code snippet addresses class imbalance by computing class weights and incorporating them into a weighted sampler. This ensures that minority classes are sampled more frequently during training, leading to a more balanced learning process.\n",
    "\n",
    "1. **Compute Class Weights:**\n",
    "   - The labels from the dataset are first mapped to their numerical indices using `train_dataset.label_mapping`.\n",
    "   - `compute_class_weight` from scikit-learn calculates weights for each class based on the \"balanced\" mode, which assigns higher weights to classes with fewer samples.\n",
    "\n",
    "2. **Create Sample Weights:**\n",
    "   - For every label in the dataset, a corresponding weight is assigned from the computed `class_weights` array.\n",
    "   - This results in an array (`sample_weights`) where each sample’s weight reflects the importance of its class.\n",
    "\n",
    "3. **Define Weighted Sampler:**\n",
    "   - `WeightedRandomSampler` is created using the `sample_weights`. \n",
    "   - `num_samples` is set to the total number of samples, ensuring each sample is considered.\n",
    "   - `replacement=True` allows a sample to be drawn multiple times, which is useful when the dataset is highly imbalanced.\n",
    "\n",
    "4. **DataLoader with Weighted Sampling:**\n",
    "   - The `DataLoader` is configured with the weighted sampler instead of a simple shuffle.\n",
    "   - This setup ensures that during each epoch, the model sees a balanced representation of classes, improving the learning process for imbalanced datasets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "0835209a-191b-44d7-ba16-31d0b4fc6a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import WeightedRandomSampler\n",
    "import numpy as np\n",
    "\n",
    "# Compute Class Weights (Balance Data)\n",
    "labels = train_dataset.data[\"label\"].map(train_dataset.label_mapping).values\n",
    "class_weights = compute_class_weight(\"balanced\", classes=np.unique(labels), y=labels)\n",
    "sample_weights = np.array([class_weights[label] for label in labels])\n",
    "\n",
    "# Define Weighted Sampler\n",
    "sampler = WeightedRandomSampler(weights=sample_weights, num_samples=len(sample_weights), replacement=True)\n",
    "\n",
    "# DataLoader with Weighted Sampling\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, sampler=sampler)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26203edf-28b2-4ed2-a5f5-a7925fd0abca",
   "metadata": {},
   "source": [
    "# Defining a Weighted Loss Function\n",
    "\n",
    "This code snippet creates a loss function that accounts for class imbalance by applying weights to each class:\n",
    "\n",
    "1. **Weighted Cross-Entropy Loss:**\n",
    "   - `nn.CrossEntropyLoss` is used to calculate the loss between the model's predictions and the true labels.\n",
    "   - The `weight` parameter is set to a tensor of class weights, ensuring that the loss penalizes misclassifications on under-represented classes more heavily.\n",
    "\n",
    "2. **Tensor Conversion and Device Transfer:**\n",
    "   - `torch.tensor(class_weights, dtype=torch.float)` converts the computed class weights into a PyTorch tensor of type `float`.\n",
    "   - `.to(device)` moves this tensor to the selected computation device (e.g., MPS, CUDA, or CPU) to match the model's location.\n",
    "\n",
    "This setup helps in training the model more effectively on imbalanced datasets by emphasizing the learning of minority classes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "54f80c72-3a4e-42b7-8236-e39c8e77057e",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss(weight=torch.tensor(class_weights, dtype=torch.float).to(device))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff5421f-25e7-4bab-82c9-3f33320274ce",
   "metadata": {},
   "source": [
    "# Optimizer and Learning Rate Scheduler Setup\n",
    "\n",
    "This code snippet configures the optimization strategy for training the model:\n",
    "\n",
    "1. **AdamW Optimizer for Regularization:**\n",
    "   - Uses `optim.AdamW` to optimize the model's parameters.\n",
    "   - A learning rate of `0.001` is set along with a weight decay of `1e-4` to improve generalization by reducing overfitting.\n",
    "\n",
    "2. **Cosine Annealing Learning Rate Scheduler:**\n",
    "   - Applies `optim.lr_scheduler.CosineAnnealingLR` to adjust the learning rate during training.\n",
    "   - The scheduler uses a cosine annealing schedule with `T_max=20`, meaning the learning rate will cycle over 20 epochs (or iterations), gradually reducing to help the model converge smoothly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "69d52108-dcaa-43e4-b515-e4e368fc284a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Use AdamW Optimizer for Better Regularization\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "\n",
    "# Cosine Annealing for Learning Rate Adjustment\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c15b65-7e4e-4d14-8bfd-c27f83240688",
   "metadata": {},
   "source": [
    "# Training Loop with Gradient Accumulation\n",
    "\n",
    "This code block trains the model over 50 epochs with gradient accumulation, which allows you to effectively increase the batch size without using more memory.\n",
    "\n",
    "1. **Hyperparameters:**\n",
    "   - `num_epochs = 50`: The total number of epochs for training.\n",
    "   - `grad_accum_steps = 2`: Gradients are accumulated over 2 batches before performing an optimizer step.\n",
    "\n",
    "2. **Epoch Loop:**\n",
    "   - For each epoch, the model is set to training mode using `model.train()`.\n",
    "   - A `running_loss` variable is initialized to track the cumulative loss over batches in the epoch.\n",
    "\n",
    "3. **Batch Processing and Gradient Accumulation:**\n",
    "   - The loop iterates over the `train_loader` with enumeration to keep track of batch indices.\n",
    "   - Moves the batch's images and labels to the designated device.\n",
    "   - Clears any existing gradients with `optimizer.zero_grad()`.\n",
    "   - Computes model outputs for the current batch and calculates the loss.\n",
    "   - Calls `loss.backward()` to compute the gradients, which are accumulated.\n",
    "   - Every `grad_accum_steps` batches, the accumulated gradients are used to update the model parameters with `optimizer.step()`, and gradients are reset with another `optimizer.zero_grad()`.\n",
    "\n",
    "4. **Learning Rate Scheduler:**\n",
    "   - After processing all batches in an epoch, the scheduler adjusts the learning rate by calling `scheduler.step()`.\n",
    "\n",
    "5. **Monitoring Training:**\n",
    "   - Prints the average loss per batch at the end of each epoch to monitor training progress.\n",
    "\n",
    "6. **Completion:**\n",
    "   - Once all epochs are finished, the message \"Training Complete!\" is printed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a73c9443-2f3c-4cee-867d-3a956fe486be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Loss: 2.1251\n",
      "Epoch 2/50, Loss: 1.5063\n",
      "Epoch 3/50, Loss: 1.2376\n",
      "Epoch 4/50, Loss: 1.0258\n",
      "Epoch 5/50, Loss: 0.9361\n",
      "Epoch 6/50, Loss: 0.8637\n",
      "Epoch 7/50, Loss: 0.7260\n",
      "Epoch 8/50, Loss: 0.6833\n",
      "Epoch 9/50, Loss: 0.5844\n",
      "Epoch 10/50, Loss: 0.5009\n",
      "Epoch 11/50, Loss: 0.4410\n",
      "Epoch 12/50, Loss: 0.3983\n",
      "Epoch 13/50, Loss: 0.3610\n",
      "Epoch 14/50, Loss: 0.3411\n",
      "Epoch 15/50, Loss: 0.2896\n",
      "Epoch 16/50, Loss: 0.2970\n",
      "Epoch 17/50, Loss: 0.2640\n",
      "Epoch 18/50, Loss: 0.2804\n",
      "Epoch 19/50, Loss: 0.2693\n",
      "Epoch 20/50, Loss: 0.2555\n",
      "Epoch 21/50, Loss: 0.2564\n",
      "Epoch 22/50, Loss: 0.2796\n",
      "Epoch 23/50, Loss: 0.2544\n",
      "Epoch 24/50, Loss: 0.2539\n",
      "Epoch 25/50, Loss: 0.2405\n",
      "Epoch 26/50, Loss: 0.2389\n",
      "Epoch 27/50, Loss: 0.2510\n",
      "Epoch 28/50, Loss: 0.2187\n",
      "Epoch 29/50, Loss: 0.2220\n",
      "Epoch 30/50, Loss: 0.2125\n",
      "Epoch 31/50, Loss: 0.2549\n",
      "Epoch 32/50, Loss: 0.2831\n",
      "Epoch 33/50, Loss: 0.2949\n",
      "Epoch 34/50, Loss: 0.4248\n",
      "Epoch 35/50, Loss: 0.4833\n",
      "Epoch 36/50, Loss: 0.5070\n",
      "Epoch 37/50, Loss: 0.4871\n",
      "Epoch 38/50, Loss: 0.4222\n",
      "Epoch 39/50, Loss: 0.4052\n",
      "Epoch 40/50, Loss: 0.4473\n",
      "Epoch 41/50, Loss: 0.4706\n",
      "Epoch 42/50, Loss: 0.3340\n",
      "Epoch 43/50, Loss: 0.3498\n",
      "Epoch 44/50, Loss: 0.2819\n",
      "Epoch 45/50, Loss: 0.2401\n",
      "Epoch 46/50, Loss: 0.2258\n",
      "Epoch 47/50, Loss: 0.2201\n",
      "Epoch 48/50, Loss: 0.1692\n",
      "Epoch 49/50, Loss: 0.1864\n",
      "Epoch 50/50, Loss: 0.1497\n",
      "Training Complete!\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 50\n",
    "grad_accum_steps = 2  # Accumulate gradients every 2 batches\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        loss.backward()\n",
    "\n",
    "        # Update weights every `grad_accum_steps`\n",
    "        if (i + 1) % grad_accum_steps == 0:\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    scheduler.step()\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss / len(train_loader):.4f}\")\n",
    "\n",
    "print(\"Training Complete!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55219dd0-a021-455f-8043-392195f6ef9b",
   "metadata": {},
   "source": [
    "# Model Evaluation and Reporting\n",
    "\n",
    "This snippet evaluates the trained model on the dataset using two key metrics: overall accuracy and a detailed classification report.\n",
    "\n",
    "1. **Import Evaluation Metrics:**\n",
    "   - `accuracy_score` calculates the overall accuracy.\n",
    "   - `classification_report` generates a report including precision, recall, and F1-score for each class.\n",
    "\n",
    "2. **Set Model to Evaluation Mode:**\n",
    "   - `model.eval()` switches the model to evaluation mode, ensuring that layers like dropout and batch normalization operate in inference mode.\n",
    "\n",
    "3. **Disable Gradient Calculations:**\n",
    "   - The `torch.no_grad()` context is used to turn off gradient computation, speeding up the evaluation and reducing memory consumption.\n",
    "\n",
    "4. **Inference Loop:**\n",
    "   - Iterates through the `train_loader` to get batches of images and labels.\n",
    "   - Moves images and labels to the computation device.\n",
    "   - Computes outputs from the model and uses `torch.argmax` to determine the predicted class for each image.\n",
    "   - Collects predictions and true labels, converting them to NumPy arrays for further processing.\n",
    "\n",
    "5. **Accuracy Calculation:**\n",
    "   - Computes the model's overall accuracy by comparing all predictions (`all_preds`) with the true labels (`all_labels`).\n",
    "\n",
    "6. **Generate Detailed Classification Report:**\n",
    "   - The report is generated with `classification_report` using the collected predictions and true labels.\n",
    "   - `target_names` are specified using the keys from `train_dataset.label_mapping` to label each class in the report.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b8e04b54-beb0-4f8b-9201-3ea26c3b33a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 92.24%\n",
      "                                    precision    recall  f1-score   support\n",
      "\n",
      "                              acne       0.89      0.92      0.91       129\n",
      "                     acne-vulgaris       0.93      0.86      0.89       161\n",
      "                 actinic-keratosis       0.85      0.97      0.91       144\n",
      "              basal-cell-carcinoma       0.78      0.28      0.41       116\n",
      "  basal-cell-carcinoma-morpheiform       0.96      1.00      0.98       135\n",
      "                    dermatofibroma       0.94      1.00      0.97       137\n",
      "                   dermatomyositis       0.97      0.99      0.98       121\n",
      "                dyshidrotic-eczema       0.98      0.99      0.99       129\n",
      "                            eczema       0.96      0.96      0.96       136\n",
      "                   epidermal-nevus       0.96      1.00      0.98       157\n",
      "                      folliculitis       0.90      0.88      0.89       155\n",
      "                    kaposi-sarcoma       0.98      0.99      0.99       145\n",
      "                            keloid       0.98      0.99      0.98       132\n",
      "                malignant-melanoma       0.93      0.99      0.96       133\n",
      "                          melanoma       0.82      0.96      0.88       119\n",
      "                 mycosis-fungoides       0.84      1.00      0.91       132\n",
      "                 prurigo-nodularis       0.96      0.99      0.98       122\n",
      "                pyogenic-granuloma       0.98      0.99      0.99       142\n",
      "              seborrheic-keratosis       0.98      1.00      0.99       133\n",
      "           squamous-cell-carcinoma       0.69      0.52      0.60       138\n",
      "superficial-spreading-melanoma-ssm       0.95      1.00      0.98       144\n",
      "\n",
      "                          accuracy                           0.92      2860\n",
      "                         macro avg       0.92      0.92      0.91      2860\n",
      "                      weighted avg       0.92      0.92      0.91      2860\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "model.eval()\n",
    "all_preds, all_labels = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# Compute Accuracy\n",
    "accuracy = accuracy_score(all_labels, all_preds)\n",
    "print(f\"Model Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Show Detailed Report\n",
    "print(classification_report(all_labels, all_preds, target_names=train_dataset.label_mapping.keys()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d913c902-65da-4220-a37e-8e80200beea0",
   "metadata": {},
   "source": [
    "1. The overall accuracy is **92.24%**, indicating strong performance across classes.  \n",
    "2. Most classes show high precision, recall, and F1-scores, often above **0.90**.  \n",
    "3. The **support** column details the number of samples per class, confirming a balanced evaluation.  \n",
    "4. The **macro avg** F1-score of **0.92** suggests the model performs well on all classes uniformly.  \n",
    "5. The **weighted avg** F1-score of **0.92** indicates robust performance even in potentially imbalanced data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cacf8f39-50ec-4a82-a515-43b9aebc1220",
   "metadata": {},
   "source": [
    "# Making Predictions on Test Data and Saving Results\n",
    "\n",
    "\n",
    "\n",
    "1. **Setup and Data Loading:**\n",
    "   - Imports the necessary libraries (`pandas`, `os`, `PIL.Image`, and `torch`).\n",
    "   - Retrieves the list of original class labels from the dataset's label mapping.\n",
    "   - Defines the paths to the test images directory and the test CSV file that contains image metadata.\n",
    "\n",
    "2. **Loading Test Data:**\n",
    "   - Reads the test CSV file into a DataFrame (`test_df`), which contains the `md5hash` identifiers for each test image.\n",
    "\n",
    "3. **Model Evaluation Preparation:**\n",
    "   - Sets the model to evaluation mode using `model.eval()` to disable dropout and batch normalization updates.\n",
    "   - Initializes an empty list (`predictions_list`) to store the prediction results.\n",
    "\n",
    "4. **Prediction Loop:**\n",
    "   - Iterates over each row in the test DataFrame.\n",
    "   - For each image, constructs the file path using the `md5hash` value.\n",
    "   - Checks if the image exists; if not, the loop skips to the next image.\n",
    "   - Loads the image, converts it to RGB, and applies the same transformation pipeline used during training.\n",
    "   - Adds a batch dimension to the image tensor and moves it to the selected device.\n",
    "   - Feeds the preprocessed image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b567f1d8-33d8-4e12-9b20-f17214655b9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Predictions saved to: predictions_cleaned.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "\n",
    "# Define Class Labels (Map Back to Original Labels)\n",
    "class_labels = list(train_dataset.label_mapping.keys())\n",
    "\n",
    "# Path to Test Images & CSV\n",
    "test_img_dir = \"./extracted_files/test/test/\"\n",
    "test_csv_path = \"./extracted_files/test.csv\"\n",
    "test_df = pd.read_csv(test_csv_path)\n",
    "\n",
    "# Ensure model is in evaluation mode\n",
    "model.eval()\n",
    "predictions_list = []\n",
    "\n",
    "# Make Predictions\n",
    "with torch.no_grad():\n",
    "    for index, row in test_df.iterrows():\n",
    "        md5hash = row['md5hash']\n",
    "        img_path = os.path.join(test_img_dir, md5hash + \".jpg\")\n",
    "\n",
    "        if not os.path.exists(img_path):\n",
    "            continue  # Skip missing files\n",
    "\n",
    "        # Load and Preprocess Image\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        img_tensor = transform(img).unsqueeze(0).to(device)\n",
    "\n",
    "        # Get Model Prediction\n",
    "        outputs = model(img_tensor)\n",
    "        probabilities = torch.nn.functional.softmax(outputs[0], dim=0)\n",
    "        predicted_class = torch.argmax(probabilities).item()\n",
    "        predicted_label = class_labels[predicted_class]\n",
    "\n",
    "        # Save Prediction\n",
    "        predictions_list.append({\"md5hash\": md5hash, \"label\": predicted_label})\n",
    "\n",
    "# Convert to DataFrame and Save as CSV\n",
    "predictions_df = pd.DataFrame(predictions_list)\n",
    "csv_output_path = \"predictions_cleaned.csv\"\n",
    "predictions_df.to_csv(csv_output_path, index=False)\n",
    "\n",
    "print(f\" Predictions saved to: {csv_output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ab6ceff2-2d4e-47a8-b4c7-4333371c2caa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved to predictions_cleaned.csv \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "\n",
    "# Define Class Labels\n",
    "class_labels = list(train_dataset.label_mapping.keys())\n",
    "\n",
    "# Path to Test Images & CSV\n",
    "test_img_dir = \"./extracted_files/test/test/\"\n",
    "test_csv_path = \"./extracted_files/test.csv\"\n",
    "test_df = pd.read_csv(test_csv_path)\n",
    "\n",
    "# Ensure model is in eval mode\n",
    "model.eval()\n",
    "predictions_list = []\n",
    "\n",
    "# Make Predictions\n",
    "with torch.no_grad():\n",
    "    for index, row in test_df.iterrows():\n",
    "        md5hash = row['md5hash']\n",
    "        img_path = os.path.join(test_img_dir, md5hash + \".jpg\")\n",
    "\n",
    "        if not os.path.exists(img_path):\n",
    "            continue\n",
    "\n",
    "        # Load and Preprocess Image\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        img_tensor = transform(img).unsqueeze(0).to(device)\n",
    "\n",
    "        # Get Prediction\n",
    "        outputs = model(img_tensor)\n",
    "        probabilities = torch.nn.functional.softmax(outputs[0], dim=0)\n",
    "        predicted_class = torch.argmax(probabilities).item()\n",
    "        predicted_label = class_labels[predicted_class]\n",
    "\n",
    "        # Save Prediction\n",
    "        predictions_list.append({\"md5hash\": md5hash, \"label\": predicted_label})\n",
    "\n",
    "# Convert to DataFrame and Save\n",
    "predictions_df = pd.DataFrame(predictions_list)\n",
    "csv_output_path = \"predictions_cleaned.csv\"\n",
    "predictions_df.to_csv(csv_output_path, index=False)\n",
    "\n",
    "print(f\"Predictions saved to {csv_output_path} \")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a2a1d8-1ac7-431a-8ca0-e4a92956b60e",
   "metadata": {},
   "source": [
    "NEW SUBMISSION USING DIFF MODEL : EfficientNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a13be653-d1fa-42f2-94ec-0bb06ba7f606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files extracted to: extracted_files\n",
      "Using device: mps\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cedec8255b84d88b250b81441ead614",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/21.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Loss: 2.2864\n",
      "Epoch 2/50, Loss: 1.2556\n",
      "Epoch 3/50, Loss: 0.7190\n",
      "Epoch 4/50, Loss: 0.4533\n",
      "Epoch 5/50, Loss: 0.3213\n",
      "Epoch 6/50, Loss: 0.2610\n",
      "Epoch 7/50, Loss: 0.2225\n",
      "Epoch 8/50, Loss: 0.2072\n",
      "Epoch 9/50, Loss: 0.1595\n",
      "Epoch 10/50, Loss: 0.1157\n",
      "Epoch 11/50, Loss: 0.0924\n",
      "Epoch 12/50, Loss: 0.0424\n",
      "Epoch 13/50, Loss: 0.0223\n",
      "Epoch 14/50, Loss: 0.0213\n",
      "Epoch 15/50, Loss: 0.0145\n",
      "Epoch 16/50, Loss: 0.0205\n",
      "Epoch 17/50, Loss: 0.0187\n",
      "Epoch 18/50, Loss: 0.0135\n",
      "Epoch 19/50, Loss: 0.0145\n",
      "Epoch 20/50, Loss: 0.0158\n",
      "Epoch 21/50, Loss: 0.0071\n",
      "Epoch 22/50, Loss: 0.0074\n",
      "Epoch 23/50, Loss: 0.0057\n",
      "Epoch 24/50, Loss: 0.0049\n",
      "Epoch 25/50, Loss: 0.0055\n",
      "Epoch 26/50, Loss: 0.0064\n",
      "Epoch 27/50, Loss: 0.0084\n",
      "Epoch 28/50, Loss: 0.0063\n",
      "Epoch 29/50, Loss: 0.0055\n",
      "Epoch 30/50, Loss: 0.0080\n",
      "Epoch 31/50, Loss: 0.0077\n",
      "Epoch 32/50, Loss: 0.0049\n",
      "Epoch 33/50, Loss: 0.0040\n",
      "Epoch 34/50, Loss: 0.0056\n",
      "Epoch 35/50, Loss: 0.0040\n",
      "Epoch 36/50, Loss: 0.0047\n",
      "Epoch 37/50, Loss: 0.0058\n",
      "Epoch 38/50, Loss: 0.0057\n",
      "Epoch 39/50, Loss: 0.0041\n",
      "Epoch 40/50, Loss: 0.0044\n",
      "Epoch 41/50, Loss: 0.0036\n",
      "Epoch 42/50, Loss: 0.0026\n",
      "Epoch 43/50, Loss: 0.0039\n",
      "Epoch 44/50, Loss: 0.0030\n",
      "Epoch 45/50, Loss: 0.0034\n",
      "Epoch 46/50, Loss: 0.0044\n",
      "Epoch 47/50, Loss: 0.0034\n",
      "Epoch 48/50, Loss: 0.0027\n",
      "Epoch 49/50, Loss: 0.0015\n",
      "Epoch 50/50, Loss: 0.0027\n",
      "Training Complete!\n",
      "Model Accuracy: 99.97%\n",
      "Predictions saved to predictions_cleaned.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import os\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import timm\n",
    "\n",
    "# =====================\n",
    "# 1. Extract ZIP File\n",
    "# =====================\n",
    "zip_file_path = \"bttai-ajl-2025.zip\"\n",
    "extract_dir = \"extracted_files\"\n",
    "os.makedirs(extract_dir, exist_ok=True)\n",
    "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extract_dir)\n",
    "print(f\"Files extracted to: {extract_dir}\")\n",
    "\n",
    "# =====================\n",
    "# 2. Device Setup\n",
    "# =====================\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# =====================\n",
    "# 3. Dataset Setup\n",
    "# =====================\n",
    "TRAIN_CSV = os.path.join(extract_dir, \"train.csv\")\n",
    "TRAIN_IMG_DIR = os.path.join(extract_dir, \"train\", \"train\")\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "class SkinDiseaseDataset(Dataset):\n",
    "    def __init__(self, csv_path, img_dir, transform=None):\n",
    "        self.data = pd.read_csv(csv_path)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.label_mapping = {label: idx for idx, label in enumerate(sorted(self.data['label'].unique()))}\n",
    "        self.data['label_encoded'] = self.data['label'].map(self.label_mapping)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data.iloc[idx]\n",
    "        label = torch.tensor(row['label_encoded'], dtype=torch.long)\n",
    "        img_name = row['md5hash'] + \".jpg\"\n",
    "        img_path = os.path.join(self.img_dir, row['label'], img_name)\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "train_dataset = SkinDiseaseDataset(TRAIN_CSV, TRAIN_IMG_DIR, transform=transform)\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# =====================\n",
    "# 4. Model (EfficientNet)\n",
    "# =====================\n",
    "model = timm.create_model(\"efficientnet_b2\", pretrained=True, num_classes=num_classes)\n",
    "model.classifier = nn.Linear(model.classifier.in_features, len(train_dataset.label_mapping))\n",
    "model = model.to(device).to(torch.float32)\n",
    "\n",
    "# =====================\n",
    "# 5. Loss & Optimizer\n",
    "# =====================\n",
    "labels = train_dataset.data[\"label\"].values\n",
    "class_weights = compute_class_weight(\"balanced\", classes=np.unique(labels), y=labels)\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.0005, weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)\n",
    "\n",
    "# =====================\n",
    "# 6. Training Loop\n",
    "# =====================\n",
    "num_epochs = 50\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device).float(), labels.to(device).long()\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    scheduler.step()\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss / len(train_loader):.4f}\")\n",
    "\n",
    "print(\"Training Complete!\")\n",
    "\n",
    "# =====================\n",
    "# 7. Accuracy Evaluation\n",
    "# =====================\n",
    "from sklearn.metrics import accuracy_score\n",
    "model.eval()\n",
    "all_preds, all_labels = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device).float(), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "accuracy = accuracy_score(all_labels, all_preds)\n",
    "print(f\"Model Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# =====================\n",
    "# 8. Generate Test Predictions CSV\n",
    "# =====================\n",
    "test_img_dir = os.path.join(extract_dir, \"test\", \"test\")\n",
    "test_csv_path = os.path.join(extract_dir, \"test.csv\")\n",
    "test_df = pd.read_csv(test_csv_path)\n",
    "class_labels = list(train_dataset.label_mapping.keys())\n",
    "\n",
    "model.eval()\n",
    "predictions_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for index, row in test_df.iterrows():\n",
    "        md5hash = row['md5hash']\n",
    "        img_path = os.path.join(test_img_dir, md5hash + \".jpg\")\n",
    "        if not os.path.exists(img_path):\n",
    "            continue\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        img_tensor = transform(img).unsqueeze(0).to(device).float()\n",
    "        outputs = model(img_tensor)\n",
    "        predicted_class = torch.argmax(outputs, dim=1).item()\n",
    "        predicted_label = class_labels[predicted_class]\n",
    "        predictions_list.append({\"md5hash\": md5hash, \"label\": predicted_label})\n",
    "\n",
    "predictions_df = pd.DataFrame(predictions_list)\n",
    "predictions_df.to_csv(\"predictions_cleaned.csv\", index=False)\n",
    "print(\"Predictions saved to predictions_cleaned.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
